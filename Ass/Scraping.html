<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <link href="/src/styles.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

  </head>
  <body>
    <script src="/src/nav.js"></script>
    <div w3-include-html="/src/nav.html"></div>
    <script> includeHTML();</script>

<div class="hmmm">
    <!-- Easter EGG: Naomi has a cat named Hera that lives with her.  -->
  </div>
  <div class="main">

  <h1>Let's learn how to webscrape! </h1>
  <h2 id="a.-github.">What is Webscraping</h2>
  <p> web scraping is a tool that allows you to get information from websites and turn it into data that you can manipulate and draw analysis from. We eventually will want to visualize the data that we get. </p>
  <h2>A. Google Colab</h2>
  <p> We mainly use google colab for web scraping because it allows people to write code collaboratively and easier than GitHub.
  Search up Google colab</p>
  <p>Then you are going to want to press new notebook. Which can be found under file.
name the notebook and share with me
</p>
<p>Name the notebook: Y/N Crimtech Webscraping and share it with naomi_kenyatta@crimson.com and KEVIN's crimson email.
</p>
  <h2>B. BeautifulSoup and Requests</h2>
  <p> For this assignment you should choose your favorite harvard department and find the website that has a list of staff members such as math.harvard.edu/people/. After
  choosing the website we are going to use the library called Beutiful Soup to collect information from the website.
  In the first code block you are going to import the library so we can use it</p>
  <pre><code>import requests
from bs4 import BeautifulSoup</code></pre>
<p> we can run this code block by pushing the run button on the left side of the block. A green arrow will appear after running showing that it was completed.
It is typically standard to have imports in a seperate code box. So now we want to press the +code button on the top of page to create a new code box.</p>
<p></p>
<h2>C. Inspect</h2>
<p>Our goal is to collect the information of the names, offices and link of every member of a department. We can navigate back towards the website choosen at the begining.
If you right click on any website there will be an option called inspect. When you click on inspect it will show you about the elements of the webpage.
Pay around with it and become comfortable naviagting around. Eventually we want to find the information that we need to click. You can do this
by naviagting throught the inspect or right clicking on the piece of information that you want and then inspect will open up to where that information is held.
You should notice that when you hover over a piece of code the corresponding part of the website is highlighted. at the begining of every line theere is an arrow pointing
either to the right or down. If the arrow is pointing right or you see ... then that means the block can be opened more by pressing the arrow or double clicking.</p>
<p> </p>
<center>
<img src="/Pic/Auroux.png" alt="Inspect" width="650" height="500">
<!-- Easter EGG: Auroux was both KL and NK's teacher last year  -->
</center>


<p></p>
<p>To get auroux's email we see that it is inside the tag called icon icon email. Now we want to collect everyones's email so we will go back to colab and in our new block</p>
<pre><code>URL = url
page = requests.get(URL)

soup = BeautifulSoup(page.content, 'html.parser')
results = soup.find_all(class_=‘name’)
results
</code></pre>
<p>You should see a large list under the block after running. This is the information from inside results. You will probably notice that the list has a lot of other random information that we dont wan’t.
A big part of web scraping is data cleaning. If you want to learn more about how BeautifulSoup and requests work you can read this: LINK MEDIUM PAGE OR SMTH. A brief explanation is that soup now holds all the information from inspect which is the websites HTML and XML pages.
Now we can use find_all to find any tags that we want and turns it into a list.
<h2>D. Data Cleaning</h2>
<i>HINT: Since we want to find 3 pieces of information for each person we should consider choosing a class that holds all of the information for example it would be info in the picture above.
Then when cleaning using .find_all() 3 times on the these blocks.</i>
<p> You should make a new block for data cleaning so that you dont have to request the webpage everytime. Now its time to use the python skills.
By the end you want to have a list of lists. For example: [["aurox", "SC 539", auroux@math.harvard.edu], ...] which has every person in a department. If a piece of information is missing, put a 0 as a place holder. </p>
<p> Another helpful function to use is</p>
<pre><code>results[0].text.strip()
  results[0].get_text();
  results[0].get('href')
</code></pre>
<p>This is two ways to get out the piece of information inbetween the tags. The .get function allows you to get information from inside the tags such as a link.
  A friendly reminder is google will be your best friend for programming. If you want to find out how to do something a quick google search will help, but always feel free to ask NK or KL for help.</p>
<i>HINT: You might need to use Try Except</i>
<pre><code>
  Try:
      results[0].text.strip()
  Except Attribute Error:
      #what should it do if you get this error. Maybe figure out what is causing this error.
</code></pre>
<p> by: Naomi Kenyatta </p>
  </div>
  <h2>E. Pandas</h2>



    <!-- BootStrap Shit -->
    <!-- Optional JavaScript -->
    <!-- jQuery first, then Popper.js, then Bootstrap JS -->
  <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
  <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>
  </body>
</html>
